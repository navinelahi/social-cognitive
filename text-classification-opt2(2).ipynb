{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n# !pip install transformers==4.21\nimport wandb\n%env WANDB_PROJECT=OPT_Text_Classification\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"e7f35459-c042-4118-9308-e4b0de23e037","_cell_guid":"a6164d28-c9e7-4bfa-aa2b-51bdd60b4432","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T11:10:08.079791Z","iopub.execute_input":"2022-09-01T11:10:08.081084Z","iopub.status.idle":"2022-09-01T11:10:08.096980Z","shell.execute_reply.started":"2022-09-01T11:10:08.081040Z","shell.execute_reply":"2022-09-01T11:10:08.095706Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"env: WANDB_PROJECT=OPT_Text_Classification\n/kaggle/input/bemas-project/train.csv\n/kaggle/input/bemas-project/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/bemas-project/train.csv\")\ntest = pd.read_csv(\"../input/bemas-project/test.csv\")\nval = test.iloc[0:100]\ntest = test.iloc[101:]\n\n\ntrain_texts=train[\"message\"].values.tolist()\nval_texts = val[\"message\"].values.tolist()\ntrain_labels=train[\"labels\"].values.tolist()\nval_labels=val[\"labels\"].values.tolist()\ntest_texts=test[\"message\"].values.tolist()\ntest_labels=test[\"labels\"].values.tolist()\n\n\nl1 = []\n\nfor i in train_labels:\n    if i==\"Yes\":\n        l1.append(1)\n    else:\n        l1.append(0)\n\nl2 = []\nfor i in val_labels:\n    if i==\"Yes\":\n        l2.append(1)\n    else:\n        l2.append(0)\n    \n\nl3 = []\nfor i in test_labels:\n    if i==\"Yes\":\n        l3.append(1)\n    else:\n        l3.append(0)\n\ntrain_labels = l1.copy()\nval_labels = l2.copy()\ntest_labels = l3.copy()\n# print(train_texts)","metadata":{"_uuid":"5911854b-06ac-44f5-8127-a560334743fa","_cell_guid":"bd0e202f-b7c4-4b4b-bb95-0d69f4d9942c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T11:10:08.099840Z","iopub.execute_input":"2022-09-01T11:10:08.100535Z","iopub.status.idle":"2022-09-01T11:10:08.127600Z","shell.execute_reply.started":"2022-09-01T11:10:08.100500Z","shell.execute_reply":"2022-09-01T11:10:08.126735Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from transformers import GPT2Tokenizer\ntokenizer = GPT2Tokenizer.from_pretrained('facebook/opt-125m', batched=True)","metadata":{"_uuid":"327a931e-6985-4be2-b525-e1832bcdaf19","_cell_guid":"562933e3-adfe-4683-a667-acab643cfee2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T11:10:08.129600Z","iopub.execute_input":"2022-09-01T11:10:08.130281Z","iopub.status.idle":"2022-09-01T11:10:10.249217Z","shell.execute_reply.started":"2022-09-01T11:10:08.130245Z","shell.execute_reply":"2022-09-01T11:10:10.248172Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"loading file https://huggingface.co/facebook/opt-125m/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/a047788adc333d1c9ea27f0685a699665269b5b28c818d27bc5c10e9406491c6.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\nloading file https://huggingface.co/facebook/opt-125m/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c20b2086e29c267013167e7a833dd17832de9ee6d724a4f4165962b005e4cd68.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\nloading file https://huggingface.co/facebook/opt-125m/resolve/main/added_tokens.json from cache at None\nloading file https://huggingface.co/facebook/opt-125m/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/45eb88dfd61e3579b84a15ad3cf2636d01e121b5474ad8944761aae4a66c62ea.c7cc7d24e97c79eaf304e87679fffb4f36cf739d549738da5cc604bf047de6ce\nloading file https://huggingface.co/facebook/opt-125m/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/5e5217fea1b769b69a0f305c0180ec5c464969f817850bfbce157a29d7ecdbf9.54de7f5b4b5bd7e3ac5035740eb559a2d3ae70659ba65ce7610b9999cd20dc53\nloading configuration file https://huggingface.co/facebook/opt-125m/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8cc575ca4de298d186c89e2901ab76d16d44c199423b0759d658328abcbdd0cd.2a47ada990dde0d9edec3a77f0bfa418a1b0b20381f5d809d00b8d5306d9a09d\nModel config OPTConfig {\n  \"_name_or_path\": \"facebook/opt-125m\",\n  \"_remove_final_layer_norm\": false,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"relu\",\n  \"architectures\": [\n    \"OPTForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 2,\n  \"do_layer_norm_before\": true,\n  \"dropout\": 0.1,\n  \"eos_token_id\": 2,\n  \"ffn_dim\": 3072,\n  \"hidden_size\": 768,\n  \"init_std\": 0.02,\n  \"layerdrop\": 0.0,\n  \"max_position_embeddings\": 2048,\n  \"model_type\": \"opt\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 1,\n  \"prefix\": \"</s>\",\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.21.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 50272,\n  \"word_embed_proj_dim\": 768\n}\n\n","output_type":"stream"}]},{"cell_type":"code","source":"train_encodings = tokenizer(train_texts, truncation=True, padding=True)\nval_encodings = tokenizer(val_texts, truncation=True, padding=True)\ntest_encodings = tokenizer(test_texts, truncation=True, padding=True)","metadata":{"_uuid":"760aae2e-6192-4061-af8c-a54b3c812e4d","_cell_guid":"90e79ce7-4ba7-47db-8636-96e9ef438406","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T11:10:10.251803Z","iopub.execute_input":"2022-09-01T11:10:10.252266Z","iopub.status.idle":"2022-09-01T11:10:10.576256Z","shell.execute_reply.started":"2022-09-01T11:10:10.252228Z","shell.execute_reply":"2022-09-01T11:10:10.575286Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n\nclass IMDbDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = IMDbDataset(train_encodings, train_labels)\nval_dataset = IMDbDataset(val_encodings, val_labels)\ntest_dataset = IMDbDataset(test_encodings, test_labels)","metadata":{"_uuid":"01578462-9a29-4bc7-a4f0-4dd729f04b2d","_cell_guid":"d3b28c80-34f6-4a76-aa02-6167f7aa65f2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T11:10:10.577939Z","iopub.execute_input":"2022-09-01T11:10:10.578306Z","iopub.status.idle":"2022-09-01T11:10:10.587009Z","shell.execute_reply.started":"2022-09-01T11:10:10.578271Z","shell.execute_reply":"2022-09-01T11:10:10.586100Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# !pip install evaluate\n# def compute_metrics(eval_pred):\n#     logits, labels = eval_pred\n#     predictions = np.argmax(logits, axis=-1)\n#     return metric.compute(predictions=predictions, references=labels)","metadata":{"_uuid":"ebf927f1-5de7-4639-8772-0b7819b41135","_cell_guid":"904a3046-5945-49c4-afe8-8972d47eff2a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T11:10:10.588694Z","iopub.execute_input":"2022-09-01T11:10:10.589358Z","iopub.status.idle":"2022-09-01T11:10:10.597225Z","shell.execute_reply.started":"2022-09-01T11:10:10.589321Z","shell.execute_reply":"2022-09-01T11:10:10.596221Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# !pip install evaluate","metadata":{"_uuid":"ba504f9f-900f-4b65-b3c4-bc849957fd0b","_cell_guid":"8c33f8d9-963c-4705-bca8-b7823d78d004","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T11:10:10.598651Z","iopub.execute_input":"2022-09-01T11:10:10.599138Z","iopub.status.idle":"2022-09-01T11:10:10.607704Z","shell.execute_reply.started":"2022-09-01T11:10:10.599103Z","shell.execute_reply":"2022-09-01T11:10:10.606739Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# !transformers-cli env\nfrom transformers import OPTForCausalLM\n\nfrom transformers import OPTForSequenceClassification, Trainer, TrainingArguments","metadata":{"_uuid":"3747866c-1b66-4e2f-9005-4bd9c344aa9e","_cell_guid":"65a78cd0-1240-48a6-a2b8-4c02f7bfed04","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T11:10:10.609116Z","iopub.execute_input":"2022-09-01T11:10:10.609591Z","iopub.status.idle":"2022-09-01T11:10:10.618636Z","shell.execute_reply.started":"2022-09-01T11:10:10.609557Z","shell.execute_reply":"2022-09-01T11:10:10.617568Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# trainer.evaluate()\nfrom transformers import TrainerCallback\n\nclass CustomCallback(TrainerCallback):\n    \n    def __init__(self, trainer) -> None:\n        super().__init__()\n        self._trainer = trainer\n    \n    def on_epoch_end(self, args, state, control, **kwargs):\n        if control.should_evaluate:\n            control_copy = deepcopy(control)\n            self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train\")\n            return control_copy","metadata":{"_uuid":"d6741730-60e7-4dba-979f-a09bc19ed974","_cell_guid":"7e5eeaef-349b-4607-9a90-e1549dc9b965","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T11:10:10.620016Z","iopub.execute_input":"2022-09-01T11:10:10.621097Z","iopub.status.idle":"2022-09-01T11:10:10.630702Z","shell.execute_reply.started":"2022-09-01T11:10:10.621030Z","shell.execute_reply":"2022-09-01T11:10:10.629651Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from datasets import load_metric\n\n# metric = load_metric(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    metrics = [\"accuracy\", \"recall\", \"precision\", \"f1\"] #List of metrics to return\n    metric={}\n    for met in metrics:\n       metric[met] = load_metric(met)\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    metric_res={}\n    for met in metrics:\n       metric_res[met]=metric[met].compute(predictions=predictions, references=labels)[met]\n    return metric_res\n\n# def compute_metrics(eval_pred):\n#     logits, labels = eval_pred\n#     predictions = np.argmax(logits, axis=-1)\n#     return metric.compute(predictions=predictions, references=labels)\n\nmodel = OPTForSequenceClassification.from_pretrained(\"facebook/opt-125m\")\n# training_args = TrainingArguments(\"test\")\ntraining_args = TrainingArguments(\n    output_dir='./opt_distilbert_text_class',          # output directory\n    num_train_epochs=3,              # total number of training epochs\n    per_device_train_batch_size=2,  # batch size per device during training\n    per_device_eval_batch_size=2,   # batch size for evaluation\n    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir='./logs',            # directory for storing logs\n    logging_steps=10,\n    report_to=\"wandb\",\n)\n\n# training_args = TrainingArguments(\"test\", evaluation_strategy=\"no\")\ntrainer       = Trainer(\n    model         = model, \n    args          = training_args, \n    train_dataset = train_dataset, \n    eval_dataset  = val_dataset,\n    compute_metrics = compute_metrics,\n)\ntrainer.add_callback(CustomCallback(trainer)) \ntrainer.train()\ntrainer.evaluate()\nwandb.finish()","metadata":{"_uuid":"39617a20-3247-4682-9e1f-75d49d6ce702","_cell_guid":"623a3b65-88b3-43ae-b110-0550504dd105","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-01T11:11:58.476260Z","iopub.execute_input":"2022-09-01T11:11:58.476631Z","iopub.status.idle":"2022-09-01T11:13:10.787559Z","shell.execute_reply.started":"2022-09-01T11:11:58.476600Z","shell.execute_reply":"2022-09-01T11:13:10.786648Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"loading configuration file https://huggingface.co/facebook/opt-125m/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8cc575ca4de298d186c89e2901ab76d16d44c199423b0759d658328abcbdd0cd.2a47ada990dde0d9edec3a77f0bfa418a1b0b20381f5d809d00b8d5306d9a09d\nModel config OPTConfig {\n  \"_name_or_path\": \"facebook/opt-125m\",\n  \"_remove_final_layer_norm\": false,\n  \"activation_dropout\": 0.0,\n  \"activation_function\": \"relu\",\n  \"architectures\": [\n    \"OPTForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 2,\n  \"do_layer_norm_before\": true,\n  \"dropout\": 0.1,\n  \"eos_token_id\": 2,\n  \"ffn_dim\": 3072,\n  \"hidden_size\": 768,\n  \"init_std\": 0.02,\n  \"layerdrop\": 0.0,\n  \"max_position_embeddings\": 2048,\n  \"model_type\": \"opt\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 1,\n  \"prefix\": \"</s>\",\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.21.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 50272,\n  \"word_embed_proj_dim\": 768\n}\n\nloading weights file https://huggingface.co/facebook/opt-125m/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/7d9862eddb69fa0b501f54f8383a6e5068d544c95ef1b76ee5e2888829acfd7a.eb503f2639ec99affd215d406e1135c43599426cb093e8a3aa4b8fb36964bf98\nSome weights of the model checkpoint at facebook/opt-125m were not used when initializing OPTForSequenceClassification: ['lm_head.weight']\n- This IS expected if you are initializing OPTForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing OPTForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-125m and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nPyTorch: setting up devices\n/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 437\n  Num Epochs = 3\n  Instantaneous batch size per device = 2\n  Total train batch size (w. parallel, distributed & accumulation) = 2\n  Gradient Accumulation steps = 1\n  Total optimization steps = 657\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='657' max='657' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [657/657 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>0.925600</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.659400</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.689600</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.699800</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.659400</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.768000</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.641200</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.493200</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>1.031800</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.756200</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.719200</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.497300</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.880200</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.664700</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.620900</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.612100</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>1.295100</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>2.253600</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.822600</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.586300</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.450900</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.762900</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.513500</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.673700</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.165000</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.398300</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.691500</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.072300</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.747800</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.305500</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>1.465200</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.569400</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>1.232500</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.451200</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.763600</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.585500</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>1.916500</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>1.581400</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.423700</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.634600</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.802200</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>2.051200</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>0.456800</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>1.914600</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.016700</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.749000</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>0.443800</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.260100</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>0.008300</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.133600</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>0.572700</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.519100</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>0.567900</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>1.210200</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>1.031700</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>0.070600</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>0.548400</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>0.278700</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>0.628200</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.288600</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>0.623600</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>0.885500</td>\n    </tr>\n    <tr>\n      <td>630</td>\n      <td>0.037500</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>0.291800</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.096300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to ./opt/checkpoint-500\nConfiguration saved in ./opt/checkpoint-500/config.json\nModel weights saved in ./opt/checkpoint-500/pytorch_model.bin\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n***** Running Evaluation *****\n  Num examples = 100\n  Batch size = 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 00:00]\n    </div>\n    "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁██</td></tr><tr><td>eval/f1</td><td>▁██</td></tr><tr><td>eval/loss</td><td>▁▂█</td></tr><tr><td>eval/precision</td><td>▁██</td></tr><tr><td>eval/recall</td><td>▁▁▁</td></tr><tr><td>eval/runtime</td><td>█▁▂</td></tr><tr><td>eval/samples_per_second</td><td>▁█▇</td></tr><tr><td>eval/steps_per_second</td><td>▁▂█</td></tr><tr><td>train/epoch</td><td>▁▂▂▃▃▃▄▅▅▆█▁▂▂▂▃▄▄▅▅▆▆▇▇█▁▁▂▂▃▄▄▄▅▆▆▇▇██</td></tr><tr><td>train/global_step</td><td>▁▂▂▃▃▃▄▅▅▆▃▁▂▂▃▃▄▄▅▅▆▆▇▇█▁▁▂▃▃▄▄▄▅▆▆▇▇▇█</td></tr><tr><td>train/learning_rate</td><td>▁▂▂▃▃▄▅▅▆▇▇▁▂▃▃▄▄▅▆▆▇█▇▅▃▁▂▂▃▃▄▅▅▆▇▇█▆▄▁</td></tr><tr><td>train/loss</td><td>▃▃▃▂▇▃▂▂▃▇▃▃▃▄▅▂▁▃▃▂▂▂▃▃▃▁▃▃▃█▃▁▃▃▃▃▄▅▂▂</td></tr><tr><td>train/total_flos</td><td>▁▁▁▁</td></tr><tr><td>train/train_loss</td><td>▂▁██</td></tr><tr><td>train/train_runtime</td><td>▁▁██</td></tr><tr><td>train/train_samples_per_second</td><td>██▁▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁▁██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.8</td></tr><tr><td>eval/f1</td><td>0.66667</td></tr><tr><td>eval/loss</td><td>1.20018</td></tr><tr><td>eval/precision</td><td>0.8</td></tr><tr><td>eval/recall</td><td>0.57143</td></tr><tr><td>eval/runtime</td><td>2.6476</td></tr><tr><td>eval/samples_per_second</td><td>37.77</td></tr><tr><td>eval/steps_per_second</td><td>18.885</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>657</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0963</td></tr><tr><td>train/total_flos</td><td>118424076337152.0</td></tr><tr><td>train/train_loss</td><td>0.7031</td></tr><tr><td>train/train_runtime</td><td>62.112</td></tr><tr><td>train/train_samples_per_second</td><td>21.107</td></tr><tr><td>train/train_steps_per_second</td><td>10.578</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Synced <strong style=\"color:#cdcd00\">./results</strong>: <a href=\"https://wandb.ai/elahinavin/huggingface/runs/zuw5nizu\" target=\"_blank\">https://wandb.ai/elahinavin/huggingface/runs/zuw5nizu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20220901_105856-zuw5nizu/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"_uuid":"a0257563-f0ee-496c-b8c3-b42c16583317","_cell_guid":"bd5c14d9-d356-48e7-90cc-4e8bf84dcc0e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}
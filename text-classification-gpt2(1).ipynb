{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n!pip install transformers==4.21\nimport wandb\n# %env WANDB_PROJECT=OPT_Text_Classification\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"e7f35459-c042-4118-9308-e4b0de23e037","_cell_guid":"a6164d28-c9e7-4bfa-aa2b-51bdd60b4432","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-02T05:08:40.323896Z","iopub.execute_input":"2022-09-02T05:08:40.324490Z","iopub.status.idle":"2022-09-02T05:09:02.483446Z","shell.execute_reply.started":"2022-09-02T05:08:40.324372Z","shell.execute_reply":"2022-09-02T05:09:02.481333Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting transformers==4.21\n  Downloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.21) (2021.11.10)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.21) (3.7.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.21) (0.8.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.21) (6.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.21) (4.64.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.21) (4.12.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.21) (2.28.1)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.21) (0.12.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.21) (1.21.6)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.21) (21.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.21) (4.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers==4.21) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.21) (3.8.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.21) (2022.6.15)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.21) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.21) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.21) (2.1.0)\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.20.1\n    Uninstalling transformers-4.20.1:\n      Successfully uninstalled transformers-4.20.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nallennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\nallennlp 2.10.0 requires transformers<4.21,>=4.1, but you have transformers 4.21.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed transformers-4.21.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m/kaggle/input/bemas-project/train.csv\n/kaggle/input/bemas-project/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/bemas-project/train.csv\")\ntest = pd.read_csv(\"../input/bemas-project/test.csv\")\nval = test.iloc[0:100]\ntest = test.iloc[101:]\n\n\ntrain_texts=train[\"message\"].values.tolist()\nval_texts = val[\"message\"].values.tolist()\ntrain_labels=train[\"labels\"].values.tolist()\nval_labels=val[\"labels\"].values.tolist()\ntest_texts=test[\"message\"].values.tolist()\ntest_labels=test[\"labels\"].values.tolist()\n\n\nl1 = []\n\nfor i in train_labels:\n    if i==\"Yes\":\n        l1.append(1)\n    else:\n        l1.append(0)\n\nl2 = []\nfor i in val_labels:\n    if i==\"Yes\":\n        l2.append(1)\n    else:\n        l2.append(0)\n    \n\nl3 = []\nfor i in test_labels:\n    if i==\"Yes\":\n        l3.append(1)\n    else:\n        l3.append(0)\n\ntrain_labels = l1.copy()\nval_labels = l2.copy()\ntest_labels = l3.copy()\n# print(train_texts)","metadata":{"_uuid":"5911854b-06ac-44f5-8127-a560334743fa","_cell_guid":"bd0e202f-b7c4-4b4b-bb95-0d69f4d9942c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-02T05:09:02.486216Z","iopub.execute_input":"2022-09-02T05:09:02.488008Z","iopub.status.idle":"2022-09-02T05:09:02.526917Z","shell.execute_reply.started":"2022-09-02T05:09:02.487948Z","shell.execute_reply":"2022-09-02T05:09:02.525775Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from transformers import GPT2Tokenizer\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\ntokenizer.padding_side = \"left\"\n# Define PAD Token = EOS Token = 50256\ntokenizer.pad_token = tokenizer.eos_token\n# tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n# tokenizer.add_special_tokens({'pad_token': '[PAD]'})","metadata":{"_uuid":"327a931e-6985-4be2-b525-e1832bcdaf19","_cell_guid":"562933e3-adfe-4683-a667-acab643cfee2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-02T05:09:02.528796Z","iopub.execute_input":"2022-09-02T05:09:02.529254Z","iopub.status.idle":"2022-09-02T05:09:06.901271Z","shell.execute_reply.started":"2022-09-02T05:09:02.529212Z","shell.execute_reply":"2022-09-02T05:09:06.900087Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading vocab.json:   0%|          | 0.00/0.99M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1ac94e84e3549c98a31ec4543f7f988"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a331849eb69e49d49487ab7a44e81536"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5e72ffb5b3749e894ae12b747a91f44"}},"metadata":{}}]},{"cell_type":"code","source":"train_encodings = tokenizer(train_texts, truncation=True, padding=True)\nval_encodings = tokenizer(val_texts, truncation=True, padding=True)\ntest_encodings = tokenizer(test_texts, truncation=True, padding=True)","metadata":{"_uuid":"760aae2e-6192-4061-af8c-a54b3c812e4d","_cell_guid":"90e79ce7-4ba7-47db-8636-96e9ef438406","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-02T05:09:06.904517Z","iopub.execute_input":"2022-09-02T05:09:06.905011Z","iopub.status.idle":"2022-09-02T05:09:07.427455Z","shell.execute_reply.started":"2022-09-02T05:09:06.904968Z","shell.execute_reply":"2022-09-02T05:09:07.426332Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch\n\nclass IMDbDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = IMDbDataset(train_encodings, train_labels)\nval_dataset = IMDbDataset(val_encodings, val_labels)\ntest_dataset = IMDbDataset(test_encodings, test_labels)","metadata":{"_uuid":"01578462-9a29-4bc7-a4f0-4dd729f04b2d","_cell_guid":"d3b28c80-34f6-4a76-aa02-6167f7aa65f2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-02T05:09:07.428902Z","iopub.execute_input":"2022-09-02T05:09:07.429513Z","iopub.status.idle":"2022-09-02T05:09:09.241139Z","shell.execute_reply.started":"2022-09-02T05:09:07.429473Z","shell.execute_reply":"2022-09-02T05:09:09.239922Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# !pip install evaluate\n# def compute_metrics(eval_pred):\n#     logits, labels = eval_pred\n#     predictions = np.argmax(logits, axis=-1)\n#     return metric.compute(predictions=predictions, references=labels)","metadata":{"_uuid":"ebf927f1-5de7-4639-8772-0b7819b41135","_cell_guid":"904a3046-5945-49c4-afe8-8972d47eff2a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-02T05:09:09.243195Z","iopub.execute_input":"2022-09-02T05:09:09.244021Z","iopub.status.idle":"2022-09-02T05:09:09.249788Z","shell.execute_reply.started":"2022-09-02T05:09:09.243975Z","shell.execute_reply":"2022-09-02T05:09:09.248642Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# !pip install evaluate","metadata":{"_uuid":"ba504f9f-900f-4b65-b3c4-bc849957fd0b","_cell_guid":"8c33f8d9-963c-4705-bca8-b7823d78d004","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-02T05:09:09.251906Z","iopub.execute_input":"2022-09-02T05:09:09.252969Z","iopub.status.idle":"2022-09-02T05:09:09.259253Z","shell.execute_reply.started":"2022-09-02T05:09:09.252926Z","shell.execute_reply":"2022-09-02T05:09:09.257967Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# !transformers-cli env\n# from transformers import OPTForCausalLM\n\nfrom transformers import GPT2ForSequenceClassification, Trainer, TrainingArguments","metadata":{"_uuid":"3747866c-1b66-4e2f-9005-4bd9c344aa9e","_cell_guid":"65a78cd0-1240-48a6-a2b8-4c02f7bfed04","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-02T05:09:09.261387Z","iopub.execute_input":"2022-09-02T05:09:09.262278Z","iopub.status.idle":"2022-09-02T05:09:14.666481Z","shell.execute_reply.started":"2022-09-02T05:09:09.262218Z","shell.execute_reply":"2022-09-02T05:09:14.665326Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trainer.evaluate()\nfrom transformers import TrainerCallback\n\nclass CustomCallback(TrainerCallback):\n    \n    def __init__(self, trainer) -> None:\n        super().__init__()\n        self._trainer = trainer\n    \n    def on_epoch_end(self, args, state, control, **kwargs):\n        if control.should_evaluate:\n            control_copy = deepcopy(control)\n            self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train\")\n            return control_copy","metadata":{"_uuid":"d6741730-60e7-4dba-979f-a09bc19ed974","_cell_guid":"7e5eeaef-349b-4607-9a90-e1549dc9b965","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-02T05:09:14.668086Z","iopub.execute_input":"2022-09-02T05:09:14.668992Z","iopub.status.idle":"2022-09-02T05:09:14.677765Z","shell.execute_reply.started":"2022-09-02T05:09:14.668951Z","shell.execute_reply":"2022-09-02T05:09:14.676694Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from datasets import load_metric\n\n# metric = load_metric(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    metrics = [\"accuracy\", \"recall\", \"precision\", \"f1\"] #List of metrics to return\n    metric={}\n    for met in metrics:\n       metric[met] = load_metric(met)\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    metric_res={}\n    for met in metrics:\n       metric_res[met]=metric[met].compute(predictions=predictions, references=labels)[met]\n    return metric_res\n\n# def compute_metrics(eval_pred):\n#     logits, labels = eval_pred\n#     predictions = np.argmax(logits, axis=-1)\n#     return metric.compute(predictions=predictions, references=labels)\n\nmodel = GPT2ForSequenceClassification.from_pretrained(\"gpt2\")\n\n# resize model embedding to match new tokenizer\nmodel.resize_token_embeddings(len(tokenizer))\n\n# fix model padding token id\nmodel.config.pad_token_id = model.config.eos_token_id\n\n# training_args = TrainingArguments(\"test\")\ntraining_args = TrainingArguments(\n    output_dir='./gpt2_text_class',          # output directory\n    num_train_epochs=3,              # total number of training epochs\n    per_device_train_batch_size=2,  # batch size per device during training\n    per_device_eval_batch_size=2,   # batch size for evaluation\n    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir='./logs',            # directory for storing logs\n    logging_steps=10,\n    report_to=\"wandb\",\n)\n\n# training_args = TrainingArguments(\"test\", evaluation_strategy=\"no\")\ntrainer       = Trainer(\n    model         = model, \n    args          = training_args, \n    train_dataset = train_dataset, \n    eval_dataset  = val_dataset,\n    compute_metrics = compute_metrics,\n)\ntrainer.add_callback(CustomCallback(trainer)) \ntrainer.train()\ntrainer.evaluate()\nwandb.finish()","metadata":{"_uuid":"39617a20-3247-4682-9e1f-75d49d6ce702","_cell_guid":"623a3b65-88b3-43ae-b110-0550504dd105","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-02T05:10:26.229109Z","iopub.execute_input":"2022-09-02T05:10:26.229863Z","iopub.status.idle":"2022-09-02T05:11:51.470831Z","shell.execute_reply.started":"2022-09-02T05:10:26.229809Z","shell.execute_reply":"2022-09-02T05:11:51.469629Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\nModel config GPT2Config {\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"GPT2LMHeadModel\"\n  ],\n  \"attn_pdrop\": 0.1,\n  \"bos_token_id\": 50256,\n  \"embd_pdrop\": 0.1,\n  \"eos_token_id\": 50256,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"gpt2\",\n  \"n_ctx\": 1024,\n  \"n_embd\": 768,\n  \"n_head\": 12,\n  \"n_inner\": null,\n  \"n_layer\": 12,\n  \"n_positions\": 1024,\n  \"reorder_and_upcast_attn\": false,\n  \"resid_pdrop\": 0.1,\n  \"scale_attn_by_inverse_layer_idx\": false,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50\n    }\n  },\n  \"transformers_version\": \"4.21.0\",\n  \"use_cache\": true,\n  \"vocab_size\": 50257\n}\n\nloading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\nAll model checkpoint weights were used when initializing GPT2ForSequenceClassification.\n\nSome weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nPyTorch: setting up devices\n/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 437\n  Num Epochs = 3\n  Instantaneous batch size per device = 2\n  Total train batch size (w. parallel, distributed & accumulation) = 2\n  Gradient Accumulation steps = 1\n  Total optimization steps = 657\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='657' max='657' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [657/657 01:12, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>0.887300</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.846700</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.838500</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.701200</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.848300</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.754600</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.793900</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.732400</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.792300</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.720900</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.705400</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.676200</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.823300</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.716200</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.617700</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.628700</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.962700</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.852900</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.858900</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.692900</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.615900</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.671200</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.616700</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.915200</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.765400</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.579000</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.666500</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.817800</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.716600</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.765500</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>0.688200</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.630300</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>0.665500</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.670600</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.195300</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.494100</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>0.675700</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.685600</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.645000</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.621400</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.731300</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.820200</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>0.594300</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.883000</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.959800</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.697900</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>0.593100</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.630600</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>0.357600</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.016000</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>1.322000</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.628500</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>0.776900</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>0.575000</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.687800</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>0.347700</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>0.962200</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>1.116600</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>0.689500</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.495400</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>0.588000</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>0.895700</td>\n    </tr>\n    <tr>\n      <td>630</td>\n      <td>0.501100</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>0.501700</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.747100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to ./gpt2_text_class/checkpoint-500\nConfiguration saved in ./gpt2_text_class/checkpoint-500/config.json\nModel weights saved in ./gpt2_text_class/checkpoint-500/pytorch_model.bin\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n***** Running Evaluation *****\n  Num examples = 100\n  Batch size = 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 00:01]\n    </div>\n    "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.41k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1397ec744a4a43c1b532f0943fd104a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d73ee83f974463ba13fc84874d228bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e4975392f5b4dea9fdbc67dcff61044"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.06k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a236aa3cd67d4a339ce9a8c22cb24f80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇███▇▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>▅▅▄▅▄▄▄▃▄▃▅▅▃▃▃▄▃▄▄▃▃▇▃▃▃▄▃▅▄▃▆█▄▃▁▇▂▃▂▄</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.61</td></tr><tr><td>eval/f1</td><td>0.09302</td></tr><tr><td>eval/loss</td><td>0.82303</td></tr><tr><td>eval/precision</td><td>0.25</td></tr><tr><td>eval/recall</td><td>0.05714</td></tr><tr><td>eval/runtime</td><td>4.306</td></tr><tr><td>eval/samples_per_second</td><td>23.223</td></tr><tr><td>eval/steps_per_second</td><td>11.612</td></tr><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/global_step</td><td>657</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7471</td></tr><tr><td>train/total_flos</td><td>117755013758976.0</td></tr><tr><td>train/train_loss</td><td>0.72886</td></tr><tr><td>train/train_runtime</td><td>72.7925</td></tr><tr><td>train/train_samples_per_second</td><td>18.01</td></tr><tr><td>train/train_steps_per_second</td><td>9.026</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Synced <strong style=\"color:#cdcd00\">./gpt2_text_class</strong>: <a href=\"https://wandb.ai/elahinavin/huggingface/runs/h9q12b4n\" target=\"_blank\">https://wandb.ai/elahinavin/huggingface/runs/h9q12b4n</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20220902_051002-h9q12b4n/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"# # resize model embedding to match new tokenizer\n# model.resize_token_embeddings(len(tokenizer))\n\n# # fix model padding token id\n# model.config.pad_token_id = model.config.eos_token_id","metadata":{"_uuid":"a0257563-f0ee-496c-b8c3-b42c16583317","_cell_guid":"bd5c14d9-d356-48e7-90cc-4e8bf84dcc0e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n!pip install transformers==4.21\nimport wandb\n# %env WANDB_PROJECT=OPT_Text_Classification\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"e7f35459-c042-4118-9308-e4b0de23e037","_cell_guid":"a6164d28-c9e7-4bfa-aa2b-51bdd60b4432","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-02T05:08:40.323896Z","iopub.execute_input":"2022-09-02T05:08:40.324490Z","iopub.status.idle":"2022-09-02T05:09:02.483446Z","shell.execute_reply.started":"2022-09-02T05:08:40.324372Z","shell.execute_reply":"2022-09-02T05:09:02.481333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/bemas-project/train.csv\")\ntest = pd.read_csv(\"../input/bemas-project/test.csv\")\nval = test.iloc[0:100]\ntest = test.iloc[101:]\n\n\ntrain_texts=train[\"message\"].values.tolist()\nval_texts = val[\"message\"].values.tolist()\ntrain_labels=train[\"labels\"].values.tolist()\nval_labels=val[\"labels\"].values.tolist()\ntest_texts=test[\"message\"].values.tolist()\ntest_labels=test[\"labels\"].values.tolist()\n\n\nl1 = []\n\nfor i in train_labels:\n    if i==\"Yes\":\n        l1.append(1)\n    else:\n        l1.append(0)\n\nl2 = []\nfor i in val_labels:\n    if i==\"Yes\":\n        l2.append(1)\n    else:\n        l2.append(0)\n    \n\nl3 = []\nfor i in test_labels:\n    if i==\"Yes\":\n        l3.append(1)\n    else:\n        l3.append(0)\n\ntrain_labels = l1.copy()\nval_labels = l2.copy()\ntest_labels = l3.copy()\n# print(train_texts)","metadata":{"_uuid":"5911854b-06ac-44f5-8127-a560334743fa","_cell_guid":"bd0e202f-b7c4-4b4b-bb95-0d69f4d9942c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-02T05:09:02.486216Z","iopub.execute_input":"2022-09-02T05:09:02.488008Z","iopub.status.idle":"2022-09-02T05:09:02.526917Z","shell.execute_reply.started":"2022-09-02T05:09:02.487948Z","shell.execute_reply":"2022-09-02T05:09:02.525775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BERTTokenizer\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\ntokenizer.padding_side = \"left\"\n# Define PAD Token = EOS Token = 50256\ntokenizer.pad_token = tokenizer.eos_token\n# tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n# tokenizer.add_special_tokens({'pad_token': '[PAD]'})","metadata":{"_uuid":"327a931e-6985-4be2-b525-e1832bcdaf19","_cell_guid":"562933e3-adfe-4683-a667-acab643cfee2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-02T05:09:02.528796Z","iopub.execute_input":"2022-09-02T05:09:02.529254Z","iopub.status.idle":"2022-09-02T05:09:06.901271Z","shell.execute_reply.started":"2022-09-02T05:09:02.529212Z","shell.execute_reply":"2022-09-02T05:09:06.900087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_encodings = tokenizer(train_texts, truncation=True, padding=True)\nval_encodings = tokenizer(val_texts, truncation=True, padding=True)\ntest_encodings = tokenizer(test_texts, truncation=True, padding=True)","metadata":{"_uuid":"760aae2e-6192-4061-af8c-a54b3c812e4d","_cell_guid":"90e79ce7-4ba7-47db-8636-96e9ef438406","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-02T05:09:06.904517Z","iopub.execute_input":"2022-09-02T05:09:06.905011Z","iopub.status.idle":"2022-09-02T05:09:07.427455Z","shell.execute_reply.started":"2022-09-02T05:09:06.904968Z","shell.execute_reply":"2022-09-02T05:09:07.426332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nclass IMDbDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = IMDbDataset(train_encodings, train_labels)\nval_dataset = IMDbDataset(val_encodings, val_labels)\ntest_dataset = IMDbDataset(test_encodings, test_labels)","metadata":{"_uuid":"01578462-9a29-4bc7-a4f0-4dd729f04b2d","_cell_guid":"d3b28c80-34f6-4a76-aa02-6167f7aa65f2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-02T05:09:07.428902Z","iopub.execute_input":"2022-09-02T05:09:07.429513Z","iopub.status.idle":"2022-09-02T05:09:09.241139Z","shell.execute_reply.started":"2022-09-02T05:09:07.429473Z","shell.execute_reply":"2022-09-02T05:09:09.239922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install evaluate\n# def compute_metrics(eval_pred):\n#     logits, labels = eval_pred\n#     predictions = np.argmax(logits, axis=-1)\n#     return metric.compute(predictions=predictions, references=labels)","metadata":{"_uuid":"ebf927f1-5de7-4639-8772-0b7819b41135","_cell_guid":"904a3046-5945-49c4-afe8-8972d47eff2a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-02T05:09:09.243195Z","iopub.execute_input":"2022-09-02T05:09:09.244021Z","iopub.status.idle":"2022-09-02T05:09:09.249788Z","shell.execute_reply.started":"2022-09-02T05:09:09.243975Z","shell.execute_reply":"2022-09-02T05:09:09.248642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install evaluate","metadata":{"_uuid":"ba504f9f-900f-4b65-b3c4-bc849957fd0b","_cell_guid":"8c33f8d9-963c-4705-bca8-b7823d78d004","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-02T05:09:09.251906Z","iopub.execute_input":"2022-09-02T05:09:09.252969Z","iopub.status.idle":"2022-09-02T05:09:09.259253Z","shell.execute_reply.started":"2022-09-02T05:09:09.252926Z","shell.execute_reply":"2022-09-02T05:09:09.257967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !transformers-cli env\n# from transformers import OPTForCausalLM\n\nfrom transformers import GPT2ForSequenceClassification, Trainer, TrainingArguments","metadata":{"_uuid":"3747866c-1b66-4e2f-9005-4bd9c344aa9e","_cell_guid":"65a78cd0-1240-48a6-a2b8-4c02f7bfed04","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-02T05:09:09.261387Z","iopub.execute_input":"2022-09-02T05:09:09.262278Z","iopub.status.idle":"2022-09-02T05:09:14.666481Z","shell.execute_reply.started":"2022-09-02T05:09:09.262218Z","shell.execute_reply":"2022-09-02T05:09:14.665326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trainer.evaluate()\nfrom transformers import TrainerCallback\n\nclass CustomCallback(TrainerCallback):\n    \n    def __init__(self, trainer) -> None:\n        super().__init__()\n        self._trainer = trainer\n    \n    def on_epoch_end(self, args, state, control, **kwargs):\n        if control.should_evaluate:\n            control_copy = deepcopy(control)\n            self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train\")\n            return control_copy","metadata":{"_uuid":"d6741730-60e7-4dba-979f-a09bc19ed974","_cell_guid":"7e5eeaef-349b-4607-9a90-e1549dc9b965","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-02T05:09:14.668086Z","iopub.execute_input":"2022-09-02T05:09:14.668992Z","iopub.status.idle":"2022-09-02T05:09:14.677765Z","shell.execute_reply.started":"2022-09-02T05:09:14.668951Z","shell.execute_reply":"2022-09-02T05:09:14.676694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_metric\n\n# metric = load_metric(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    metrics = [\"accuracy\", \"recall\", \"precision\", \"f1\"] #List of metrics to return\n    metric={}\n    for met in metrics:\n       metric[met] = load_metric(met)\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    metric_res={}\n    for met in metrics:\n       metric_res[met]=metric[met].compute(predictions=predictions, references=labels)[met]\n    return metric_res\n\n# def compute_metrics(eval_pred):\n#     logits, labels = eval_pred\n#     predictions = np.argmax(logits, axis=-1)\n#     return metric.compute(predictions=predictions, references=labels)\n\nmodel = GPT2ForSequenceClassification.from_pretrained(\"gpt2\")\n\n# resize model embedding to match new tokenizer\nmodel.resize_token_embeddings(len(tokenizer))\n\n# fix model padding token id\nmodel.config.pad_token_id = model.config.eos_token_id\n\n# training_args = TrainingArguments(\"test\")\ntraining_args = TrainingArguments(\n    output_dir='./gpt2_text_class',          # output directory\n    num_train_epochs=3,              # total number of training epochs\n    per_device_train_batch_size=2,  # batch size per device during training\n    per_device_eval_batch_size=2,   # batch size for evaluation\n    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir='./logs',            # directory for storing logs\n    logging_steps=10,\n    report_to=\"wandb\",\n)\n\n# training_args = TrainingArguments(\"test\", evaluation_strategy=\"no\")\ntrainer       = Trainer(\n    model         = model, \n    args          = training_args, \n    train_dataset = train_dataset, \n    eval_dataset  = val_dataset,\n    compute_metrics = compute_metrics,\n)\ntrainer.add_callback(CustomCallback(trainer)) \ntrainer.train()\ntrainer.evaluate()\nwandb.finish()","metadata":{"_uuid":"39617a20-3247-4682-9e1f-75d49d6ce702","_cell_guid":"623a3b65-88b3-43ae-b110-0550504dd105","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-09-02T05:10:26.229109Z","iopub.execute_input":"2022-09-02T05:10:26.229863Z","iopub.status.idle":"2022-09-02T05:11:51.470831Z","shell.execute_reply.started":"2022-09-02T05:10:26.229809Z","shell.execute_reply":"2022-09-02T05:11:51.469629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # resize model embedding to match new tokenizer\n# model.resize_token_embeddings(len(tokenizer))\n\n# # fix model padding token id\n# model.config.pad_token_id = model.config.eos_token_id","metadata":{"_uuid":"a0257563-f0ee-496c-b8c3-b42c16583317","_cell_guid":"bd5c14d9-d356-48e7-90cc-4e8bf84dcc0e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}